\documentclass{article}
\usepackage{../fasy-hw}
\usepackage{algorithmicx}

%% UPDATE these variables:
\renewcommand{\hwnum}{1}
\title{Advanced Algorithms, Homework \hwnum}
\author{Sarah Montalbano}
\collab{Ryan FitzSimmons}
\date{due: 13 September 2021}

\begin{document}

\maketitle

This homework assignment should be
submitted as a single PDF file both to D2L and to Gradescope.

General homework expectations:
\begin{itemize}
    \item Homework should be typeset using LaTex.
    \item Answers should be in complete sentences and proofread.
    \item You will not plagiarize, nor will you share your written solutions
        with classmates.
    \item List collaborators at the start of each question using the
        \texttt{collab} command.
    \item Put your answers where the \texttt{todo} command currently is (and
        remove the \texttt{todo}, but not the word \texttt{Answer}).
    \item If you are asked to come up with an algorithm, you are
        expected to give an algorithm that beats the brute force (and, if possible, of
        optimal time complexity). With your algorithm, please provide the following:
        \begin{itemize}
            \item \emph{What}: A prose explanation of the problem and the algorithm,
                including a description of the input/output.
            \item \emph{How}: Describe how the algorithm works, including giving
                psuedocode for it.  Be sure to reference the pseudocode
                from within the prose explanation.
            \item \emph{How Fast}: Runtime, along with justification.  (Or, in the
                extreme, a proof of termination).
            \item \emph{Why}: Statement of the loop invariant for each loop, or
                recursion invariant for each recursive function.
        \end{itemize}
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{Ryan FitzSimmons}
\nextprob{Groups}

Work in a group of size $\geq 2$.  Explain your strategy for working in a group.

\paragraph{Answer}{Working in a group means splitting the problems, discussing them once one of the partners has come to some sort of answer or struggled with it for long enough, and then coming to a conclusion. Then each partner types up their solution, with Sarah proofreading the entire assignment for accuracy, then returning it to Ryan to ensure that the no changes to the content were made that aren't appropriate. We completed this entire assignment through collaborative online tools rather than meeting in person. Ryan has assumed responsibility of turning in the assignment to both D2L and Gradescope (with Sarah attached as a collaborator in Gradescope).}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{Ryan FitzSimmons}
\nextprob{More Basics}

\begin{enumerate}

    \item Use the definition of big-Theta notation to prove that $f(x)=4n-5$
        is $\Theta(n+1)$.

        \paragraph{Answer}{The definition of $\Theta(n+1)$ is (from class notes) as follows: $f(x)$ is $\Theta(n+1) \Leftrightarrow \exists  n \in \mathbb{N}$ and $a, b \in \mathbb{R}$ s.t. $\forall n \geq N: b(n + 1) \leq f(x) \leq a(n + 1).$ 

We claim that there exists an $N, a, b$ s.t. $f(x) = 4n-5$ is $\Theta(n + 1).$ 

Proof: Let $a = 2$, $b = -\frac{1}{2}$, $N = 1$. Let $n \geq N$. Then $b(n+1) = -\frac{1}{2}(n+1) \leq n+1$. In addition, $n + 1 \leq a(n+1) = 2(n+1)$. 

Therefore, we have $\forall n \geq N, -\frac{1}{2}(n+1) \leq n + 1 \leq 2(n+1)$, which gives us that $f(x)$ is $\Theta(n+1)$}

    \item Use induction to prove that, for all $n \in \N$, the complete graph on
        $n$ vertices (denoted by the symbol~$K_n$) has $\frac{n(n-1)}{2}$~edges.

        \begin{proof}
	Claim: For all $n \in \N$, the complete graph on
        $n$ vertices (denoted by the symbol~$K_n$) has $\frac{n(n-1)}{2}$~edges.
	
	Base case: If $n = 1$, then $\frac{n(n-1)}{2}$ = $\frac{1(1-1)}{2}$ = $0$. A graph with $1$ vertex has $0$ edges, so the claim is true for $n = 1$.

	Inductive hypothesis: Assume that a complete graph with $k$ vertices has a total of $\frac{k(k-1)}{2}$ edges.

	Inductive step: A graph with $k + 1$ vertices has a total of $\frac{(k+1)(k+1-1)}{2}$ = $\frac{k(k+1)}{2}$. 

	By the inductive hypothesis, a graph with $k$ vertices has $\frac{k(k-1)}{2}$ edges. Add another vertex $m$ such that the graph now has $k+1$ vertices. In order to maintain the definition of a complete graph, the new edges must go from vertex $m$ to the original $k$ vertices; $k$ new edges have been added. 

	Thus, by the inductive hypothesis and the $k$ edges added to accomodate the additional vertex: 

	$\frac{k(k-1)}{2} + k$
	$= \frac{k(k-1)}{2} + \frac{2k}{2}$
	$ = \frac{k(k-1) + 2k}{2}$
	$ = \frac{k^2 - k +2k}{2} $
	$ = \frac{k^2 + k}{2}$
	$ = \frac{k(k+1)}{2}$
	
	The claim that for all $n \in \N$, the complete graph on $n$ vertices has $\frac{n(n-1)}{2}$~edges, which was to be shown.
        \end{proof}

    \item What is the negation of the following statement: for all integers $n
        \in \Z$, $n$ is prime.

        \paragraph{Answer}{There exists an integer $n \in \Z$ such that $n$ is not prime.}

\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{Ryan FitzSimmons}
\nextprob{Sorting before Searching?}
Let $A$ be an array of $n$ comparable objects.  We do not know if $A$ is sorted
or not.

\begin{enumerate}
    \item To answer the question \emph{is item $x$ in $A$?}, should we
        sort the array first?  Why or why not?

        \paragraph{Answer}{No, we should not sort the array first if searching for a single item $x$. This is because a linear search through the array of length $n$ will take $O(n)$ time regardless, and most sorting algorithms will take $O(nlogn)$ in their average case scenarios. If the array were almost sorted, a linear search would only match, not go faster, than the best-case runtimes for insertion sort ($O(n)$), and any other sorting algorithm would perform slower even in the best case. Thus, performing a linear search through the array will be faster if looking for a single item $x$.}

    \item Suppose we have $k$ elements that we want to find in $A$. Does this
        change your answer? Why or why~not?

        \paragraph{Answer}{If we are looking for $k$ elements and $k$ is sufficiently large, it will be faster to sort the array of length $n$ before searching for each $k$ element. Let's assume we use an average-case sorting algorithm with a runtime of $O(nlogn)$. The growth of $k \dot n$, for a series of linear searches, will eventually exceed the growth of $k \dot nlogn$ for a sufficiently large $k$. Thus, performing $k$ linear searches on an unsorted array will only be faster than sorting beforehand if $k$ is small.}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{Ryan FitzSimmons}
\nextprob{Recurrence Relations}
Consider the function $T \colon \N \to \N$ defined by
$$T(n) = \begin{cases}
            1        & n=1\\
            T(n-1)+1 & n>1.
         \end{cases}
$$
What is the closed form and asymptotic form of this recursion?  For the
closed form, use induction to prove that it is correct.  For the asymptotic
form, use the definition of big-Theta to justify.

\paragraph{Answer}
\begin{proof}
Claim: The closed form of $$T(n) = \begin{cases}
            1        & n=1\\
            T(n-1)+1 & n>1.
         \end{cases}
$$ is $T(n) = n$ for all $n > 1$. 

Base Case: $n = 1$. The value for $n = 1$ is given as 1. Thus, the claim that $T(n) = n$ holds for $T(1) = 1$. 

Inductive Assumption: Assume that for all $n \geq 1$, $T(k) = T(k-1) + 1$ for all $k \leq n$.

Inductive step: Let $m$ = $k - 1$. We assume that the inductive assumption holds for $T(k + 1)$. Thus: 
$T(k) = T(k-1) + 1$

$T(k + 1) = T(k - 1 - 1) + 1  + 1 = T(k - 2) + 2$

The general formula appears to be $T(k) = T(k - m) + m.$

Substituting $k-1$ for $m$: $T(k) = T(k - (k - 1)) + (k - 1).$

Simplify: $T(k) = T(k - k + 1) + k - 1.$

Cancel out the $k$: $T(k) = T(1) + k - 1.$

We know $T(1) = 1$ from the base case, and so we can substitute: $T(k) = 1 + k - 1$.

The 1s cancel: $T(k) = k$. 

Since $k = n$, $T(n) = n$.
\end{proof}

\begin{proof}
The asymptotic form of $$T(n) = \begin{cases}
            1        & n=1\\
            T(n-1)+1 & n>1.
         \end{cases}
$$ is $\Theta(n)$. 

The definition of $\Theta(n)$ is as follows: $T(n)$ is $\Theta(n) \Leftrightarrow \exists  n \in \mathbb{N}$ and $a, b \in \mathbb{R} s.t. \forall n \geq N: bn \leq T(n) \leq an.$ 

Claim: There exists an $N, a, b$ s.t. $T(n)$ satisfies $\Theta(n)$.

Proof: Let $a = 1$, $b = 1$, and $N = 1$. Let $n \geq N$. 

Then $bn = n \leq n.$ In addition, $n \leq an = n$. 

Therefore,  we have $\forall n \geq N, n \leq n \leq n$, which gives us that $T(n)$ is $\Theta(n)$
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{Ryan FitzSimmons}
\nextprob{More Recurrence Relations}

What is the asymptotic form of the following recurrence
relations? (Show work for partial credit, but full justification is not required
on this question).
Let $T \colon \N \to N$ be defined by $T(1)=1$ and, for $n>1$,
\begin{enumerate}
    \item $T(n) = 16 T(n/4) + n$
        \paragraph{Answer}{We use Master's theorem as defined below and find the case that matches. $a$ = 16, $b$ =4, ${\log_b a} = 2$, $n^{\log_b a} = n^2$. $f(n) = n$, which is less than $n^{\log_b a}$. We are thus in Case 1 and must find $\epsilon$: $n \in O(n^{2-\epsilon})$. $\epsilon = 1$ works to find a tight bound. Thus, the asymptotic form by case 1 of Master's theorem is $T(n) = 16 T(n/4) + n \in \Theta(n^2)$.}
    \item $T(n) = 2 T(n/2) + n \log{n}$
        \paragraph{Answer}{We use Master's theorem as defined below and find the case that matches. $a$ = 2, $b$ = 2, ${\log_b a} = 1$, $n^{\log_b a} = n^1$. $f(n) = nlogn$, which is greater than $n^{\log_b a}$. We are thus in Case 3 and must find both $\epsilon$ and $c$: $nlogn \in O(n^{1+\epsilon})$. $\epsilon = 1$ makes the RHS $O(n^2)$, and $nlogn$ is $\in O(n^2)$. Then we find $c$: $2f(n/2) \leq cf(n)$. Then $f(n) \leq cf(n)$, so $c = 1$ works to get a strict equality. Thus, our asymptotic form by case 3 of Master's theorem is $T(n) = 2 T(n/2) + n \log{n} \in \Theta(n \log{n})$}
    \item $T(n) = 6 T(n/3) + n^2 \log{n}$
        \paragraph{Answer}{We use Master's theorem as defined below and find the case that matches. $a$ = 6, $b$ = 3, ${\log_b a} = \frac{\log 6}{\log 3}$ and $n^{\log_b a} = n^{\frac{\log 6}{\log 3}}$. $f(n) = n^2{\log n}$, which is greater than $n^{\log_b a}$. This places us in case 3, where we must find an $\epsilon$ and a $c$: $n^2{\log n} \in O(n^{\frac{\log 6}{\log 3}+\epsilon})$. If $\epsilon = (3 - \frac{\log 6}{\log 3})$ makes the RHS is approximately $O(n^3)$, and $n^2{\log n}$ is $\in O(n^3)$. Now we find $c$: $6f(n/3) \leq cf(n) = 2f(n) \leq cf(n)$. This means $c \geq 2$. Thus the asymptotic form is  $T(n) = 6 T(n/3) + n^2 \log{n}$ = $\Theta(n^2{\log n}).$ }
    \item $T(n) = 4 T(n/2) + n^2$
        \paragraph{Answer}{We use Master's theorem as defined below to find the case that matches. $a$ = 4, $b$ = 2, ${\log_b a} = 2$, $n^{\log_b a} = n^2$. $f(n) = n^2$, which means that $n^{\log_b a} = f(n) = n^2$. We are thus in Case 2, and we do not need to find an $\epsilon$. Our asymptotic form is $T(n) = 4 T(n/2) + n^2 \in \Theta(n^2\log{n})$. }
    \item $T(n) = 9 T(n/3) + n$
        \paragraph{Answer}{We use Master's theorem as defined below and find the matching case. $a$ = 9, $b$ = 3, ${\log_b a} = 2$, $n^{\log_b a} = n^2$. $f(n) = n$, which is less than $n^{\log_b a}$. We are thus in Case 1 and we must find an $\epsilon$ that completes this statement correctly: $n \in O(n^{2-\epsilon})$. $\epsilon = 1$ creates a tight bound. The asymptotic form is thus $T(n) = 9 T(n/3) + n \in \Theta(n^2)$}
\end{enumerate}

From the Master's Theorem handout: 
Master's theorem allows us to quickly solve recurrence relations of the form:
$$ T(n) = a T(n/b) + f(n),$$
where $a, b \in \N$ such that $a \geq 1$ and $b >0$ and $f(n)$ is asymptotically
positive.  Then, we can determine the closed-form of $T(n)$ as follows:
\begin{enumerate}
    \item IF there exists $\varepsilon \in \R_+$ such that $f(n) \in O(n^{\log_b
        a - \varepsilon})$, THEN $T(n) \in \Theta(n^{\log_b a})$.
    \item IF there exists $\varepsilon \in \R_+$ such that $f(n) \in \Theta(n^{\log_b
        a})$, THEN $T(n) \in \Theta(n^{\log_b a}\log n)$.
    \item IF (1) there exists $\varepsilon \in \R_+$ such that $f(n) \in O(n^{\log_b
        a + \varepsilon})$
        and (2) there exists $c \in (0,1)$ and $n_0 \in \N$ such that for all $n
        \geq n_0$, $a f(n/b) \leq c f(n)$, THEN $T(n) \in \Theta(f(n))$.
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{\todo{}}
\nextprob{Pancakes}

Chapter 1, Problem 9, parts (a) and (b).

\paragraph{Question, Part (a)}{Describe an algorithm to sort an arbitrary stack of n pancakes using O(n) flips. Exactly how many flips does your algorithm perform in the worst case?}
\paragraph{Answer, Part (a)}{This problem requires us to sort a stack of differently-sized pancakes with larger pancakes on the bottom and smaller ones on top. The only operation at our disposal is a flip, which inserts a spatula under the top $k$ pancakes for some integer between 1 and $n$ ($n$ being the size of the stack), and flips them all over. The algorithm accepts a stack of pancakes to be sorted and returns the sorted stack  of pancakes.

The prose description of the algorithm is as follows: If the size of a stack is 0, then there are no pancakes and the stack is trivially sorted. If the size of the stack of pancakes is 1, there is one pancake and the stack is trivially sorted. For sizes of the stack greater than 1, we should flip the largest pancake $n$ to the top (line 5 in PancakeSort), flip $n$ to the bottom by flipping the whole stack (line 5), and then recurse on the top $n-1$ pancakes (line 6). The "flip" function performs the flip to its correct position above the largest pancake. maxIndex finds the index of the largest pancake. 

Psuedocode:
\begin{algorithmic}
\Function{PancakeSort}{stack}
\State $n\gets length(stack)$
\While{$n \geq 1$}
	\State maxindex = maxIndex(stack, n)
	\State flip(stack, maxindex)
	\State flip(stack, n-1)
	\State $n--$
\EndWhile
\EndFunction
\end{algorithmic}

\begin{algorithmic}
\Function{flip}{stack, m}
\State set left $\gets 0$
\While{left $<$ m}
	\State stack[left], stack[m] = stack[m], stack[left]
	\State m--
	\State left++
\EndWhile
\EndFunction
\end{algorithmic}
\begin{algorithmic}
\Function{maxIndex}{stack, m}
\State index $\gets 0$
\For{i in range(m)}
	\If {stack[i] $>$ stack[index]}
		\State index = i
	\EndIf
\EndFor
\State \Return index
\EndFunction
\end{algorithmic}

"Exactly how many flips does your algorithm perform in the worst case?" The most possible flips are $2n - 3$: there will be 2 flips per $n$ pancakes that are being sorted, so we start at $2n$. The second to last pancake only needs 1 flip to come to the top (-1) and the last pancake doesn't need either flip (-2). 

Worst-case runtime would be $\Omega(n)$ because the worst-case flips are 2n - 3, and the constant -3 and multiplication by 2 can be ignored in time analysis. (If we were factoring in the searching time represented by maxIndex, which is linear $n$ for finding the largest pancake in the stack, then worst-case runtime will be closer to $\Omega(n^2).$ -- one $n$ for the searching times one $n$ for the flipping.

The recursion invariant is: after any $k$ number of steps, the largest $k$ pancakes are in their correct positions. This would be checked right after line 7 in PancakeSort(), after each iteration of the While loop had executed.

Clarification on the problem and pseudocode from here: \url{https://en.wikipedia.org/wiki/Pancake_sorting}. Also consulted: \url{http://www.cs.cmu.edu/~venkatg/teaching/15252-sp20/notes/pancakes-notes.pdf}

\paragraph{Question, Part (b)}{For every positive integer n, describe a stack of n pancakes that requires (n) flips to sort.}
\paragraph{Answer, Part (b)}{A stack of size $n$ that is sorted in reverse, e.g. every pancake has a larger one on top of it, such that the largest is on top, will only need one flip to be perfectly sorted.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\collab{\todo{}}
\nextprob{Largest Complete Subtree}

Chapter 1, Problem 37.  For this problem, please provide a full proof of
correctness (i.e., provide a proof for the recursion invariant).

\paragraph{Question}{For this problem, a subtree of a binary tree means any connected subgraph. A binary tree is complete if every internal node has two children, and every
leaf has exactly the same depth. Describe and analyze a recursive algorithm
to compute the largest complete subtree of a given binary tree. Your algorithm
should return both the root and the depth of this subtree.}

\paragraph{Answer}{Asking for the largest complete subtree of a given binary tree is essentially asking for the complete depth at each vertice $v$. To solve this problem, we can perform a recursive postorder traversal through the graph. The base case occurs if there is no $v$ to examine (line 2, where $v$ = null). Then the else statement recursively does the algorithm on the left and right sides of the vertex (line 5 and 6) and then compares to get the minimum. The pseudocode is as follows:}

\begin{algorithmic}
\Function{completeDepth}{vertex}
\If {v = null}
\Return -1
\Else
	\State leftCompleteDepth $\gets$ completeDepth(left(vertex))
	\State rightCompleteDepth $\gets$ completeDepth(right(vertex))
	\State CD(vertex) $\gets$ min\{leftCompleteDepth, rightCompleteDepth\} + 1
	\State \Return CD(vertex)
\EndIf
\EndFunction
\end{algorithmic}

The runtime of this algorithm is $\Theta(n)$, where $n$ is the number of nodes in the tree. This is because the algorithm spends $\Theta(1)$ at each node. 

The recursion invariant is that leftCompleteDepth and rightCompleteDepth is either null or pointers to valid nodes. \todo{}

Psuedocode adapted from implementation of postorder traversal here (the concept is basically the same): \url{https://www.techiedelight.com/postorder-tree-traversal-iterative-recursive/}

Interesting paper discussion of postorder traversal loop invariants: \url{https://qrs20.techconf.org/QRSC2020_FULL/pdfs/QRS-C2020-4QOuHkY3M10ZUl1MoEzYvg/891500a669/891500a669.pdf}






\end{document}
